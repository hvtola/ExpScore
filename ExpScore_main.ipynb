{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString, Point, MultiPoint # To create line geometries that can be used in a GeoData\n",
    "import numpy as np\n",
    "import math\n",
    "from math import floor\n",
    "from osgeo import gdal, ogr\n",
    "import struct\n",
    "from shapely.ops import unary_union\n",
    "import rasterio\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORECAST = r'C:\\Users\\htla\\OneDrive - Norges vassdrags- og energidirektorat\\Artikler\\ExpScore\\avalanche-bulletin_2017-12-01--2024-06-01.csv'\n",
    "SHAPEFILE = r'C:\\Users\\htla\\OneDrive - Norges vassdrags- og energidirektorat\\Datasett (GIS)\\GPX tracks - Strava\\clean_data\\carepanel\\carepanel_tracks_final_duplicates_removed_2023_2024.shp'\n",
    "RUN_DISTANCE = r'C:\\Users\\htla\\OneDrive - Norges vassdrags- og energidirektorat\\Datasett (GIS)\\Flow-Py - Norge\\alpha_23\\runout_distance.tif'\n",
    "ExpScore_PRA = r'C:\\Users\\htla\\OneDrive - Norges vassdrags- og energidirektorat\\Datasett (GIS)\\Flow-Py - Norge\\pra.tif'\n",
    "ELEVATION = r'C:\\Users\\htla\\OneDrive - Norges vassdrags- og energidirektorat\\Datasett (GIS)\\DTM10\\dtm10_apr_int16.tif'\n",
    "SLOPE = r'C:\\Users\\htla\\OneDrive - Norges vassdrags- og energidirektorat\\Datasett (GIS)\\DTM10\\dtm10_apr_slope_int16.tif'\n",
    "REGION = r'C:\\Users\\htla\\OneDrive - Norges vassdrags- og energidirektorat\\Datasett (GIS)\\Varslingsregioner\\Varslingsregioner_1km.tif'\n",
    "ASPECT = r'C:\\Users\\htla\\OneDrive - Norges vassdrags- og energidirektorat\\Datasett (GIS)\\DTM10\\dtm10_apr_cardinal_directions.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = pd.read_csv(FORECAST)\n",
    "gdf = gpd.read_file(SHAPEFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['datetime'] = gdf['date'] + gdf['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast['Dato'] = pd.to_datetime(forecast['Dato'], format='%Y-%m-%d').dt.date\n",
    "gdf['datetime'] = pd.to_datetime(gdf['datetime'], format='%Y-%m-%d%H_%M_%S').dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def extract_string(input_string, datatype):\n",
    "    # Split the string into a list of numbers and remove '\\n'\n",
    "    string = input_string.strip(\"[]\").replace('\\n', '').split()\n",
    "    \n",
    "    # Convert the list of strings to a NumPy array of integers\n",
    "    string = np.array(string, dtype=datatype)\n",
    "    return string\n",
    "\n",
    "def get_exposed_sector(SP_asp, SP_min, SP_max, elevation, aspect, runout, pra):\n",
    "    # Correct aspect dictionary according to specified format\n",
    "    aspect_dict = {'N': 1, 'NE': 2, 'E': 3, 'SE': 4, 'S': 5, 'SW': 6, 'W': 7, 'NW': 8}\n",
    "\n",
    "    # Filter aspects based on SP1_asp\n",
    "    valid_aspects = [aspect_dict[asp] for asp in SP_asp.split(', ')]\n",
    "\n",
    "    # Filter based on corrected aspect values and updated elevation criteria\n",
    "    valid_indices = (np.isin(aspect, valid_aspects) & (elevation >= SP_min) & (elevation <= SP_max))\n",
    "    \n",
    "    # Count of valid values\n",
    "    num_valid_values = np.sum(valid_indices)\n",
    "\n",
    "    # Calculate sums for valid indices\n",
    "    count_runout = np.sum(runout[valid_indices] > 0)\n",
    "    count_pra = np.sum(pra[valid_indices] > 0)\n",
    "    sum_runout = np.sum(runout[valid_indices])\n",
    "    sum_pra = np.sum(pra[valid_indices])\n",
    "    \n",
    "    return sum_runout, sum_pra, num_valid_values, count_runout, count_pra\n",
    "\n",
    "def get_exposed_sector_two(SP1_asp, SP1_min, SP1_max, SP2_asp, SP2_min, SP2_max, elevation, aspect, runout, pra):\n",
    "    # Correct aspect dictionary according to specified format\n",
    "    aspect_dict = {'N': 1, 'NE': 2, 'E': 3, 'SE': 4, 'S': 5, 'SW': 6, 'W': 7, 'NW': 8}\n",
    "\n",
    "    # Filter aspects based on SP1_asp\n",
    "    valid_aspects1 = [aspect_dict[asp] for asp in SP1_asp.split(', ')]\n",
    "\n",
    "    # Filter based on corrected aspect values and updated elevation criteria\n",
    "    valid_indices1 = (np.isin(aspect, valid_aspects1) & (elevation >= SP1_min) & (elevation <= SP1_max))\n",
    "    \n",
    "    # Filter aspects based on SP2_asp\n",
    "    valid_aspects2 = [aspect_dict[asp] for asp in SP2_asp.split(', ')]\n",
    "\n",
    "    # Filter based on corrected aspect values and updated elevation criteria\n",
    "    valid_indices2 = (np.isin(aspect, valid_aspects2) & (elevation >= SP2_min) & (elevation <= SP2_max))\n",
    "    \n",
    "    valid_indices = valid_indices1 | valid_indices2\n",
    "    \n",
    "    # Count of valid values\n",
    "    num_valid_values = np.sum(valid_indices)\n",
    "\n",
    "    # Calculate sums for valid indices\n",
    "    count_runout = np.sum(runout[valid_indices] > 0)\n",
    "    count_pra = np.sum(pra[valid_indices] > 0)\n",
    "    sum_runout = np.sum(runout[valid_indices])\n",
    "    sum_pra = np.sum(pra[valid_indices])\n",
    "    \n",
    "    return sum_runout, sum_pra, num_valid_values, count_runout, count_pra\n",
    "\n",
    "def get_exposed_sector_three(SP1_asp, SP1_min, SP1_max, SP2_asp, SP2_min, SP2_max, SP3_asp, SP3_min, SP3_max, elevation, aspect, runout, pra):\n",
    "    # Correct aspect dictionary according to specified format\n",
    "    aspect_dict = {'N': 1, 'NE': 2, 'E': 3, 'SE': 4, 'S': 5, 'SW': 6, 'W': 7, 'NW': 8}\n",
    "\n",
    "    # Filter aspects based on SP1_asp\n",
    "    valid_aspects1 = [aspect_dict[asp] for asp in SP1_asp.split(', ')]\n",
    "\n",
    "    # Filter based on corrected aspect values and updated elevation criteria\n",
    "    valid_indices1 = (np.isin(aspect, valid_aspects1) & (elevation >= SP1_min) & (elevation <= SP1_max))\n",
    "    \n",
    "    # Filter aspects based on SP2_asp\n",
    "    valid_aspects2 = [aspect_dict[asp] for asp in SP2_asp.split(', ')]\n",
    "\n",
    "    # Filter based on corrected aspect values and updated elevation criteria\n",
    "    valid_indices2 = (np.isin(aspect, valid_aspects2) & (elevation >= SP2_min) & (elevation <= SP2_max))\n",
    "    \n",
    "    # Filter aspects based on SP2_asp\n",
    "    valid_aspects3 = [aspect_dict[asp] for asp in SP3_asp.split(', ')]\n",
    "\n",
    "    # Filter based on corrected aspect values and updated elevation criteria\n",
    "    valid_indices3 = (np.isin(aspect, valid_aspects3) & (elevation >= SP3_min) & (elevation <= SP3_max))\n",
    "    \n",
    "    valid_indices = valid_indices1 | valid_indices2 | valid_indices3\n",
    "    \n",
    "    # Count of valid values\n",
    "    num_valid_values = np.sum(valid_indices)\n",
    "\n",
    "    # Calculate sums for valid indices\n",
    "    count_runout = np.sum(runout[valid_indices] > 0)\n",
    "    count_pra = np.sum(pra[valid_indices] > 0)\n",
    "    sum_runout = np.sum(runout[valid_indices])\n",
    "    sum_pra = np.sum(pra[valid_indices])\n",
    "    \n",
    "    return sum_runout, sum_pra, num_valid_values, count_runout, count_pra\n",
    "\n",
    "def identify_aspects(SP1_asp, SP2_asp, SP3_asp):\n",
    "    # Define the possible inputs\n",
    "    possible_inputs = ['N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW']\n",
    "\n",
    "    # Initialize a set to store unique valid cardinal directions\n",
    "    unique_cardinal_directions = set()\n",
    "\n",
    "    # Collect all input strings into a list\n",
    "    input_strings = [SP1_asp, SP2_asp, SP3_asp]\n",
    "\n",
    "    # Iterate through each input string and add valid directions to the set\n",
    "    for input_str in input_strings:\n",
    "        if not pd.isna(input_str):\n",
    "            directions = input_str.split(', ')\n",
    "            for direction in directions:\n",
    "                if direction in possible_inputs:\n",
    "                    unique_cardinal_directions.add(direction)\n",
    "\n",
    "    # Create a comma-separated string from the unique valid cardinal directions\n",
    "    output_str = ', '.join(sorted(unique_cardinal_directions))\n",
    "\n",
    "    # Print the final result\n",
    "    return output_str\n",
    "\n",
    "def find_minimum(SP1_min, SP2_min, SP3_min):\n",
    "    # Create a list to store the values of SP1_min, SP2_min, and SP3_min\n",
    "    values = [SP1_min, SP2_min, SP3_min]\n",
    "\n",
    "    # Filter out None or empty values and find the minimum\n",
    "    min_value = min(filter(lambda x: x is not None and x != '', values))\n",
    "\n",
    "    return min_value\n",
    "\n",
    "def find_maximum(SP1_max, SP2_max, SP3_max):\n",
    "    # Create a list to store the values of SP1_min, SP2_min, and SP3_min\n",
    "    values = [SP1_max, SP2_max, SP3_max]\n",
    "\n",
    "    # Filter out None or empty values and find the minimum\n",
    "    max_value = max(filter(lambda x: x is not None and x != '', values))\n",
    "\n",
    "    return max_value\n",
    "\n",
    "def extract_values_from_raster(src_filename, line_gdf):\n",
    "    src_ds=gdal.Open(src_filename) \n",
    "    gt_forward=src_ds.GetGeoTransform()\n",
    "    gt_reverse=gdal.InvGeoTransform(gt_forward)\n",
    "    rb=src_ds.GetRasterBand(1)\n",
    "\n",
    "    ds=ogr.Open(line_gdf['geometry'].to_json())\n",
    "    lyr=ds.GetLayer()\n",
    "\n",
    "    li_values = list()\n",
    "    for feat in lyr:\n",
    "        geom = feat.GetGeometryRef()\n",
    "        mx,my=geom.GetX(), geom.GetY()  #coord in map units\n",
    "\n",
    "        #Convert from map to pixel coordinates.\n",
    "        px, py = gdal.ApplyGeoTransform(gt_reverse, mx, my)\n",
    "        px = floor(px) #x pixel\n",
    "        py = floor(py) #y pixel\n",
    "\n",
    "        structval=rb.ReadRaster(px,py,1,1,buf_type=gdal.GDT_UInt16) #Assumes 16 bit int aka 'short'\n",
    "        intval = struct.unpack('h' , structval) # use the 'short' format code (2 bytes) not int (4 bytes)\n",
    "        li_values.append(intval[0])\n",
    "        arr = np.array(li_values)\n",
    "    \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:7\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500\n",
      "3501\n",
      "3502\n",
      "3503\n",
      "3504\n",
      "3505\n",
      "3506\n",
      "3507\n",
      "3508\n",
      "3509\n",
      "3510\n",
      "3511\n",
      "3512\n",
      "3513\n",
      "3514\n",
      "3515\n",
      "3516\n",
      "3517\n",
      "3518\n",
      "3519\n",
      "3520\n",
      "3521\n",
      "3522\n",
      "3523\n",
      "3524\n",
      "3525\n",
      "3526\n",
      "3527\n",
      "3528\n",
      "3529\n",
      "3530\n",
      "3531\n",
      "3532\n",
      "3533\n",
      "3534\n",
      "3535\n",
      "3536\n",
      "3537\n",
      "3538\n",
      "3539\n",
      "3540\n",
      "3541\n",
      "3542\n",
      "3543\n",
      "3544\n",
      "3545\n",
      "3546\n",
      "3547\n",
      "3548\n",
      "3549\n",
      "3550\n",
      "3551\n",
      "3552\n",
      "3553\n",
      "3554\n",
      "3555\n",
      "3556\n",
      "3557\n",
      "3558\n",
      "3559\n",
      "3560\n",
      "3561\n",
      "3562\n",
      "3563\n",
      "3564\n",
      "3565\n",
      "3566\n",
      "3567\n",
      "3568\n",
      "3569\n",
      "3570\n",
      "3571\n",
      "3572\n",
      "3573\n",
      "3574\n",
      "3575\n",
      "3576\n",
      "3577\n",
      "3578\n",
      "3579\n",
      "3580\n",
      "3581\n",
      "3582\n",
      "3583\n",
      "3584\n",
      "3585\n",
      "3586\n",
      "3587\n",
      "3588\n",
      "3589\n",
      "3590\n",
      "3591\n",
      "3592\n",
      "3593\n",
      "3594\n",
      "3595\n",
      "3596\n",
      "3597\n",
      "3598\n",
      "3599\n",
      "3600\n",
      "3601\n",
      "3602\n",
      "3603\n",
      "3604\n",
      "3605\n",
      "3606\n",
      "3607\n",
      "3608\n",
      "3609\n",
      "3610\n",
      "3611\n",
      "3612\n",
      "3613\n",
      "3614\n",
      "3615\n",
      "3616\n",
      "3617\n",
      "3618\n",
      "3619\n",
      "3620\n",
      "3621\n",
      "3622\n",
      "3623\n",
      "3624\n",
      "3625\n",
      "3626\n",
      "3627\n",
      "3628\n",
      "3629\n",
      "3630\n",
      "3631\n",
      "3632\n",
      "3633\n",
      "3634\n",
      "3635\n",
      "3636\n",
      "3637\n",
      "3638\n",
      "3639\n",
      "3640\n",
      "3641\n",
      "3642\n",
      "3643\n",
      "3644\n",
      "3645\n",
      "3646\n",
      "3647\n",
      "3648\n",
      "3649\n",
      "3650\n",
      "3651\n",
      "3652\n",
      "3653\n",
      "3654\n",
      "3655\n",
      "3656\n",
      "3657\n",
      "3658\n",
      "3659\n",
      "3660\n",
      "3661\n",
      "3662\n",
      "3663\n",
      "3664\n",
      "3665\n",
      "3666\n",
      "3667\n",
      "3668\n",
      "3669\n",
      "3670\n",
      "3671\n",
      "3672\n",
      "3673\n",
      "3674\n",
      "3675\n",
      "3676\n",
      "3677\n",
      "3678\n",
      "3679\n",
      "3680\n",
      "3681\n",
      "3682\n",
      "3683\n",
      "3684\n",
      "3685\n",
      "3686\n",
      "3687\n",
      "3688\n",
      "3689\n",
      "3690\n",
      "3691\n",
      "3692\n",
      "3693\n",
      "3694\n",
      "3695\n",
      "3696\n",
      "3697\n",
      "3698\n",
      "3699\n",
      "3700\n",
      "3701\n",
      "3702\n",
      "3703\n",
      "3704\n",
      "3705\n",
      "3706\n",
      "3707\n",
      "3708\n",
      "3709\n",
      "3710\n",
      "3711\n",
      "3712\n",
      "3713\n",
      "3714\n",
      "3715\n",
      "3716\n",
      "3717\n",
      "3718\n",
      "3719\n",
      "3720\n",
      "3721\n",
      "3722\n",
      "3723\n",
      "3724\n",
      "3725\n",
      "3726\n",
      "3727\n",
      "3728\n",
      "3729\n",
      "3730\n",
      "3731\n",
      "3732\n",
      "3733\n",
      "3734\n",
      "3735\n",
      "3736\n",
      "3737\n",
      "3738\n",
      "3739\n",
      "3740\n",
      "3741\n",
      "3742\n",
      "3743\n",
      "3744\n",
      "3745\n",
      "3746\n",
      "3747\n",
      "3748\n",
      "3749\n",
      "3750\n",
      "3751\n",
      "3752\n",
      "3753\n",
      "3754\n",
      "3755\n",
      "3756\n",
      "3757\n",
      "3758\n",
      "3759\n",
      "3760\n",
      "3761\n",
      "3762\n",
      "3763\n",
      "3764\n",
      "3765\n",
      "3766\n",
      "3767\n",
      "3768\n",
      "3769\n",
      "3770\n",
      "3771\n",
      "3772\n",
      "3773\n",
      "3774\n",
      "3775\n",
      "3776\n",
      "3777\n",
      "3778\n",
      "3779\n",
      "3780\n",
      "3781\n",
      "3782\n",
      "3783\n",
      "3784\n",
      "3785\n",
      "3786\n",
      "3787\n",
      "3788\n",
      "3789\n",
      "3790\n",
      "3791\n",
      "3792\n",
      "3793\n",
      "3794\n",
      "3795\n",
      "3796\n",
      "3797\n",
      "3798\n",
      "3799\n",
      "3800\n",
      "3801\n",
      "3802\n",
      "3803\n",
      "3804\n",
      "3805\n",
      "3806\n",
      "3807\n",
      "3808\n",
      "3809\n",
      "3810\n",
      "3811\n",
      "3812\n",
      "3813\n",
      "3814\n",
      "3815\n",
      "3816\n",
      "3817\n",
      "3818\n",
      "3819\n",
      "3820\n",
      "3821\n",
      "3822\n",
      "3823\n",
      "3824\n",
      "3825\n",
      "3826\n",
      "3827\n",
      "3828\n",
      "3829\n",
      "3830\n",
      "3831\n",
      "3832\n",
      "3833\n",
      "3834\n",
      "3835\n",
      "3836\n",
      "3837\n",
      "3838\n",
      "3839\n",
      "3840\n",
      "3841\n",
      "3842\n",
      "3843\n",
      "3844\n",
      "3845\n",
      "3846\n",
      "3847\n",
      "3848\n",
      "3849\n",
      "3850\n",
      "3851\n",
      "3852\n",
      "3853\n",
      "3854\n",
      "3855\n",
      "3856\n",
      "3857\n",
      "3858\n",
      "3859\n",
      "3860\n",
      "3861\n",
      "3862\n",
      "3863\n",
      "3864\n",
      "3865\n",
      "3866\n",
      "3867\n",
      "3868\n",
      "3869\n",
      "3870\n",
      "3871\n",
      "3872\n",
      "3873\n",
      "3874\n",
      "3875\n",
      "3876\n",
      "3877\n",
      "3878\n",
      "3879\n",
      "3880\n",
      "3881\n",
      "3882\n",
      "3883\n",
      "3884\n",
      "3885\n",
      "3886\n",
      "3887\n",
      "3888\n",
      "3889\n",
      "3890\n",
      "3891\n",
      "3892\n",
      "3893\n",
      "3894\n",
      "3895\n",
      "3896\n",
      "3897\n",
      "3898\n",
      "3899\n",
      "3900\n",
      "3901\n",
      "3902\n",
      "3903\n",
      "3904\n",
      "3905\n",
      "3906\n",
      "3907\n",
      "3908\n",
      "3909\n",
      "3910\n",
      "3911\n",
      "3912\n",
      "3913\n",
      "3914\n",
      "3915\n",
      "3916\n",
      "3917\n",
      "3918\n",
      "3919\n",
      "3920\n",
      "3921\n",
      "3922\n",
      "3923\n",
      "3924\n",
      "3925\n",
      "3926\n",
      "3927\n",
      "3928\n",
      "3929\n",
      "3930\n",
      "3931\n",
      "3932\n",
      "3933\n",
      "3934\n",
      "3935\n",
      "3936\n",
      "3937\n",
      "3938\n",
      "3939\n",
      "3940\n",
      "3941\n",
      "3942\n",
      "3943\n",
      "3944\n",
      "3945\n",
      "3946\n",
      "3947\n",
      "3948\n",
      "3949\n",
      "3950\n",
      "3951\n",
      "3952\n",
      "3953\n",
      "3954\n",
      "3955\n",
      "3956\n",
      "3957\n",
      "3958\n",
      "3959\n",
      "3960\n",
      "3961\n",
      "3962\n",
      "3963\n",
      "3964\n",
      "3965\n",
      "3966\n",
      "3967\n",
      "3968\n",
      "3969\n",
      "3970\n",
      "3971\n",
      "3972\n",
      "3973\n",
      "3974\n",
      "3975\n",
      "3976\n",
      "3977\n",
      "3978\n",
      "3979\n",
      "3980\n",
      "3981\n",
      "3982\n",
      "3983\n",
      "3984\n",
      "3985\n",
      "3986\n",
      "3987\n",
      "3988\n",
      "3989\n",
      "3990\n",
      "3991\n",
      "3992\n",
      "3993\n",
      "3994\n",
      "3995\n",
      "3996\n",
      "3997\n",
      "3998\n",
      "3999\n",
      "4000\n",
      "4001\n",
      "4002\n",
      "4003\n",
      "4004\n",
      "4005\n",
      "4006\n",
      "4007\n",
      "4008\n",
      "4009\n",
      "4010\n",
      "4011\n",
      "4012\n",
      "4013\n",
      "4014\n",
      "4015\n",
      "4016\n",
      "4017\n",
      "4018\n",
      "4019\n",
      "4020\n",
      "4021\n",
      "4022\n",
      "4023\n",
      "4024\n",
      "4025\n",
      "4026\n",
      "4027\n",
      "4028\n",
      "4029\n",
      "4030\n",
      "4031\n",
      "4032\n",
      "4033\n",
      "4034\n",
      "4035\n",
      "4036\n",
      "4037\n",
      "4038\n",
      "4039\n",
      "4040\n",
      "4041\n",
      "4042\n",
      "4043\n",
      "4044\n",
      "4045\n",
      "4046\n",
      "4047\n",
      "4048\n",
      "4049\n",
      "4050\n",
      "4051\n",
      "4052\n",
      "4053\n",
      "4054\n",
      "4055\n",
      "4056\n",
      "4057\n",
      "4058\n",
      "4059\n",
      "4060\n",
      "4061\n",
      "4062\n",
      "4063\n",
      "4064\n",
      "4065\n",
      "4066\n",
      "4067\n",
      "4068\n",
      "4069\n",
      "4070\n",
      "4071\n",
      "4072\n",
      "4073\n",
      "4074\n",
      "4075\n",
      "4076\n",
      "4077\n",
      "4078\n",
      "4079\n",
      "4080\n",
      "4081\n",
      "4082\n",
      "4083\n",
      "4084\n",
      "4085\n",
      "4086\n",
      "4087\n",
      "4088\n",
      "4089\n",
      "4090\n",
      "4091\n",
      "4092\n",
      "4093\n",
      "4094\n",
      "4095\n",
      "4096\n",
      "4097\n",
      "4098\n",
      "4099\n",
      "4100\n",
      "4101\n",
      "4102\n",
      "4103\n",
      "4104\n",
      "4105\n",
      "4106\n",
      "4107\n",
      "4108\n",
      "4109\n",
      "4110\n",
      "4111\n",
      "4112\n",
      "4113\n",
      "4114\n",
      "4115\n",
      "4116\n",
      "4117\n",
      "4118\n",
      "4119\n",
      "4120\n",
      "4121\n",
      "4122\n",
      "4123\n",
      "4124\n",
      "4125\n",
      "4126\n",
      "4127\n",
      "4128\n",
      "4129\n",
      "4130\n",
      "4131\n",
      "4132\n",
      "4133\n",
      "4134\n",
      "4135\n",
      "4136\n",
      "4137\n",
      "4138\n",
      "4139\n",
      "4140\n",
      "4141\n",
      "4142\n",
      "4143\n",
      "4144\n",
      "4145\n",
      "4146\n",
      "4147\n",
      "4148\n",
      "4149\n",
      "4150\n",
      "4151\n",
      "4152\n",
      "4153\n",
      "4154\n",
      "4155\n",
      "4156\n",
      "4157\n",
      "4158\n",
      "4159\n",
      "4160\n",
      "4161\n",
      "4162\n",
      "4163\n",
      "4164\n",
      "4165\n",
      "4166\n",
      "4167\n",
      "4168\n",
      "4169\n",
      "4170\n",
      "4171\n",
      "4172\n",
      "4173\n",
      "4174\n",
      "4175\n",
      "4176\n",
      "4177\n",
      "4178\n",
      "4179\n",
      "4180\n",
      "4181\n",
      "4182\n",
      "4183\n",
      "4184\n",
      "4185\n",
      "4186\n",
      "4187\n",
      "4188\n",
      "4189\n",
      "4190\n",
      "4191\n",
      "4192\n",
      "4193\n",
      "4194\n",
      "4195\n",
      "4196\n",
      "4197\n",
      "4198\n",
      "4199\n",
      "4200\n",
      "4201\n",
      "Wall time: 2h 6min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "acc_pra = 0.75\n",
    "acc_ro = 0.25\n",
    "trip_pra = 0.1794\n",
    "trip_ro = 0.8206\n",
    "rr = (acc_ro/trip_ro)/(acc_pra/trip_pra)\n",
    "\n",
    "data = pd.DataFrame()\n",
    "\n",
    "for i in range(0, 4202, 1):\n",
    "    print(i)\n",
    "    track = gdf['geometry'][i]\n",
    "    row = gdf[['filename', 'user', 'id', 'datetime']].iloc[i:i+1]\n",
    "    date = row.iloc[0]['datetime']\n",
    "    \n",
    "    # Generate points for every 10 meter along line\n",
    "    distance_delta = 10\n",
    "    distances = np.arange(0, track.length, distance_delta)\n",
    "    points = [track.interpolate(distance) for distance in distances] + [track.boundary[1]]\n",
    "    multipoint = unary_union(points)\n",
    "    line_df = pd.DataFrame()\n",
    "    \n",
    "    line_gdf = gpd.GeoDataFrame(line_df, geometry=[multipoint,])\n",
    "    line_gdf = line_gdf.explode().reset_index(level=0).drop(['level_0'], axis=1)\n",
    "    \n",
    "    # Extract ExpScale_Runout\n",
    "    run = extract_values_from_raster(RUN_DISTANCE, line_gdf)\n",
    "    \n",
    "    run[np.where(run == 10000)] = 0\n",
    "    lam = 0.01639453\n",
    "    alpha=0.8153966\n",
    "    run = np.exp(-(lam*run)**alpha)\n",
    "    run[np.where(run == 1)] = 0\n",
    "    row['ExpScore_Runout_data'] = [run]\n",
    "    row['ExpScore_Runout'] = run.sum()\n",
    "    \n",
    "    # Extract ExpScore_PRA\n",
    "    pra = extract_values_from_raster(ExpScore_PRA, line_gdf)\n",
    "    pra[np.where(pra == 128)] = 0\n",
    "    pra = pra/100\n",
    "    new_min = rr\n",
    "    new_max = 1\n",
    "    renormalized_pra = np.where(pra == 0, 0, new_min + (new_max - new_min) * pra)\n",
    "    row['ExpScore_PRA_data'] = [renormalized_pra]\n",
    "    row['ExpScore_PRA'] = renormalized_pra.sum()\n",
    "    \n",
    "    # row['ExpScore_PRA_data'] = [pra]\n",
    "    # row['ExpScore_PRA'] = pra.sum()\n",
    "    \n",
    "    # row['ExpScore'] = (run.sum()*0.072857113)+pra.sum()\n",
    "    # row['ExpScore'] = (run.sum()*0.072)+pra.sum()\n",
    "    \n",
    "    # Extract ELEVATION\n",
    "    ele = extract_values_from_raster(ELEVATION, line_gdf)\n",
    "    # pra[np.where(pra == 128)] = 0\n",
    "    row['elevation'] = [ele]\n",
    "    row['elevation_maks'] = ele.max()\n",
    "    row['elevation_min'] = ele.min()\n",
    "    \n",
    "    # Extract SLOPE\n",
    "    slo = extract_values_from_raster(SLOPE, line_gdf)\n",
    "    # pra[np.where(pra == 128)] = 0\n",
    "    row['slope'] = [slo]\n",
    "    \n",
    "    # Extract REGION\n",
    "    reg = extract_values_from_raster(REGION, line_gdf)\n",
    "    # pra[np.where(pra == 128)] = 0\n",
    "    row['regionID'] = stats.mode(reg)[0][0]\n",
    "    \n",
    "    # Extract ASPECT\n",
    "    asp = extract_values_from_raster(ASPECT, line_gdf)\n",
    "    # pra[np.where(pra == 128)] = 0\n",
    "    row['aspect'] = [asp]\n",
    "    row['aspect_mode'] = stats.mode(asp)[0][0]\n",
    "    row['length'] = len(asp)*10\n",
    "    \n",
    "    # Filter forecast\n",
    "    region = int(row.iloc[0].regionID)\n",
    "    filtered_forecast = forecast[(forecast['Dato'] == date) & (forecast['Region-ID'] == region)]\n",
    "    filtered_forecast = filtered_forecast.fillna(np.nan)\n",
    "    \n",
    "    # Check if the DataFrame is empty\n",
    "    if filtered_forecast.empty:\n",
    "        continue\n",
    "        \n",
    "    else:\n",
    "        row['danger_level'] = filtered_forecast.iloc[0].Faregrad\n",
    "        row['SP1'] = filtered_forecast.iloc[0].SP1\n",
    "        row['SP1_size'] = filtered_forecast['Skredstørrelse SP1'].iloc[0]\n",
    "        row['SP1_distribution'] = filtered_forecast['Utbredelse SP1'].iloc[0]\n",
    "        row['SP1_sensitivity'] = filtered_forecast['Utløsbarhet SP1'].iloc[0]  \n",
    "\n",
    "        row['SP2'] = filtered_forecast.iloc[0].SP2\n",
    "        row['SP2_size'] = filtered_forecast['Skredstørrelse SP2'].iloc[0]\n",
    "        row['SP2_distribution'] = filtered_forecast['Utbredelse SP2'].iloc[0]\n",
    "        row['SP2_sensitivity'] = filtered_forecast['Utløsbarhet SP2'].iloc[0]\n",
    "\n",
    "        row['SP3'] = filtered_forecast.iloc[0].SP3\n",
    "        row['SP3_size'] = filtered_forecast['Skredstørrelse SP3'].iloc[0]\n",
    "        row['SP3_distribution'] = filtered_forecast['Utbredelse SP3'].iloc[0]\n",
    "        row['SP3_sensitivity'] = filtered_forecast['Utløsbarhet SP3'].iloc[0]\n",
    "        \n",
    "        # Extract data from string\n",
    "        row.iloc[0].elevation\n",
    "        row.iloc[0].aspect\n",
    "        row.iloc[0].ExpScore_PRA_data\n",
    "        row.iloc[0].ExpScore_Runout_data\n",
    "        \n",
    "        SP1_asp = []\n",
    "        SP1_min = []\n",
    "        SP1_max = []        \n",
    "        SP2_asp = []\n",
    "        SP2_min = []\n",
    "        SP2_max = []\n",
    "        SP3_asp = []\n",
    "        SP3_min = []\n",
    "        SP3_max = []\n",
    "\n",
    "        # SP1\n",
    "        if pd.isna(filtered_forecast.iloc[0, 8]) == True:\n",
    "            row['ExpScore_SP1_runout'] = -1\n",
    "            row['ExpScore_SP1_pra'] = -1\n",
    "            row['SP1_num_exposed_cells'] = -1\n",
    "            row['SP1_asp'] = -1\n",
    "            row['SP1_min'] = -1\n",
    "            row['SP1_max'] = -1\n",
    "            row['SP1_num_exposed_cells_runout'] = -1\n",
    "            row['SP1_num_exposed_cells_pra'] = -1\n",
    "        else:\n",
    "            row['SP1_asp'] = filtered_forecast.iloc[0, 8]\n",
    "            row['SP1_min'] = filtered_forecast.iloc[0, 9]\n",
    "            row['SP1_max'] = filtered_forecast.iloc[0, 10]\n",
    "            row['ExpScore_SP1_runout'], row['ExpScore_SP1_pra'], row['SP1_num_exposed_cells'], row['SP1_num_exposed_cells_runout'], row['SP1_num_exposed_cells_pra'] = get_exposed_sector(row.iloc[0].SP1_asp, row.iloc[0].SP1_min, row.iloc[0].SP1_max, row.iloc[0].elevation, row.iloc[0].aspect, row.iloc[0].ExpScore_Runout_data, row.iloc[0].ExpScore_PRA_data)\n",
    "\n",
    "        # SP2\n",
    "        if pd.isna(filtered_forecast.iloc[0, 15]) == True:\n",
    "            row['ExpScore_SP2_runout'] = -1\n",
    "            row['ExpScore_SP2_pra'] = -1\n",
    "            row['SP2_num_exposed_cells'] = -1\n",
    "            row['SP2_asp'] = -1\n",
    "            row['SP2_min'] = -1\n",
    "            row['SP2_max'] = -1\n",
    "            row['SP2_num_exposed_cells_runout'] = -1\n",
    "            row['SP2_num_exposed_cells_pra'] = -1\n",
    "            row['SP1_2_num_exposed_cells_runout'] = -1\n",
    "            row['SP1_2_num_exposed_cells_pra'] = -1\n",
    "            row['SP1_2_num_exposed_cells'] = -1\n",
    "            row['ExpScore_SP1_2_runout'] = -1\n",
    "            row['ExpScore_SP1_2_pra'] = -1\n",
    "        else:\n",
    "            row['SP2_asp'] = filtered_forecast.iloc[0, 15]\n",
    "            row['SP2_min'] = filtered_forecast.iloc[0, 16]\n",
    "            row['SP2_max'] = filtered_forecast.iloc[0, 17]\n",
    "            row['ExpScore_SP2_runout'], row['ExpScore_SP2_pra'], row['SP2_num_exposed_cells'], row['SP2_num_exposed_cells_runout'], row['SP2_num_exposed_cells_pra'] = get_exposed_sector(row.iloc[0].SP2_asp, row.iloc[0].SP2_min, row.iloc[0].SP2_max, row.iloc[0].elevation, row.iloc[0].aspect, row.iloc[0].ExpScore_Runout_data, row.iloc[0].ExpScore_PRA_data)\n",
    "            row['ExpScore_SP1_2_runout'], row['ExpScore_SP1_2_pra'], row['SP1_2_num_exposed_cells'], row['SP1_2_num_exposed_cells_runout'], row['SP1_2_num_exposed_cells_pra'] = get_exposed_sector_two(row.iloc[0].SP1_asp, row.iloc[0].SP1_min, row.iloc[0].SP1_max, row.iloc[0].SP2_asp, row.iloc[0].SP2_min, row.iloc[0].SP2_max, row.iloc[0].elevation, row.iloc[0].aspect, row.iloc[0].ExpScore_Runout_data, row.iloc[0].ExpScore_PRA_data)\n",
    "        # SP3\n",
    "        if pd.isna(filtered_forecast.iloc[0, 22]) == True:\n",
    "            row['ExpScore_SP3_runout'] = -1\n",
    "            row['ExpScore_SP3_pra'] = -1\n",
    "            row['SP3_num_exposed_cells'] = -1\n",
    "            row['SP3_asp'] = -1\n",
    "            row['SP3_min'] = -1\n",
    "            row['SP3_max'] = -1\n",
    "            row['SP3_num_exposed_cells_runout'] = -1\n",
    "            row['SP3_num_exposed_cells_pra'] = -1\n",
    "            row['SP1_3_num_exposed_cells_runout'] = -1\n",
    "            row['SP1_3_num_exposed_cells_pra'] = -1\n",
    "            row['SP1_3_num_exposed_cells'] = -1\n",
    "            row['ExpScore_SP1_3_runout'] = -1\n",
    "            row['ExpScore_SP1_3_pra'] = -1\n",
    "        else:\n",
    "            row['SP3_asp'] = filtered_forecast.iloc[0, 22]\n",
    "            row['SP3_min'] = filtered_forecast.iloc[0, 23]\n",
    "            row['SP3_max'] = filtered_forecast.iloc[0, 24]\n",
    "            row['ExpScore_SP3_runout'], row['ExpScore_SP3_pra'], row['SP3_num_exposed_cells'], row['SP3_num_exposed_cells_runout'], row['SP3_num_exposed_cells_pra'] = get_exposed_sector(row.iloc[0].SP3_asp, row.iloc[0].SP3_min, row.iloc[0].SP3_max, row.iloc[0].elevation, row.iloc[0].aspect, row.iloc[0].ExpScore_Runout_data, row.iloc[0].ExpScore_PRA_data)\n",
    "            row['ExpScore_SP1_3_runout'], row['ExpScore_SP1_3_pra'], row['SP1_3_num_exposed_cells'], row['SP1_3_num_exposed_cells_runout'], row['SP1_3_num_exposed_cells_pra'] = get_exposed_sector_three(row.iloc[0].SP1_asp, row.iloc[0].SP1_min, row.iloc[0].SP1_max, row.iloc[0].SP2_asp, row.iloc[0].SP2_min, row.iloc[0].SP2_max, row.iloc[0].SP3_asp, row.iloc[0].SP3_min, row.iloc[0].SP3_max, row.iloc[0].elevation, row.iloc[0].aspect, row.iloc[0].ExpScore_Runout_data, row.iloc[0].ExpScore_PRA_data)\n",
    "            \n",
    "        # print(row)\n",
    "        columns_to_drop = ['elevation', 'slope', 'aspect', 'ExpScore_PRA_data', 'ExpScore_Runout_data']  # Replace with the names of the columns you want to drop\n",
    "        row = row.drop(columns=columns_to_drop)\n",
    "        \n",
    "    data = data.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('ExpScore.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
